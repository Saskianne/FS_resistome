{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assembly steps\n",
    "\n",
    "With Shotgun-metatranscriptome-sequencing data \\\n",
    "Conda environment name: Assembly\n",
    "\n",
    "- primarly for the illumina runs, paired-end sequences\n",
    "- Steps are: \n",
    "    - QC with trimmomatic\n",
    "        - bash script: Trimmomatic_QC.sh\n",
    "    - PHIX filtering with bbmap\n",
    "    - error correction with tedpole (from bbmap package)\n",
    "    - assembly with metaSPAdes\n",
    "\n",
    "## Long-read sequencing data (e.g. PacBio) \n",
    "Conda environment name: PacBio_Assembly\n",
    "\n",
    "- for long read sequencing data from PacBio sequel platform: \n",
    "    - SRR10983239\n",
    "    - SRR10983240\n",
    "    - SRR10983241\n",
    "    - SRR10983242\n",
    "    \n",
    "- Workflow:\n",
    "    - QC using fastqc (results in RAWDATA/PacBio_runs/QC_metrics) and filtlong\n",
    "    - Assembly using wtdbg2, metaFlye, Canu and  Trycycler\n",
    "    - QC of assemblies with the metaQUAST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "module load gcc12-env/12.3.0\n",
    "module load miniconda3/24.11.1\n",
    "\n",
    "cd $WORK/DATA\n",
    "mkdir QCed_DATA PHIX_FILTERED ERROR_CORRECTED ASSEMBLIES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Progress Illumina\n",
    "\n",
    "#### Trimmomatic PE: \n",
    "- Completed successfully\n",
    "- Bigger files took longer and were interrupted often \n",
    "    - -> set longer time for the individual batch (max 48h) or launch parallel jobs\n",
    "\n",
    "#### PhiX174 Removal:\n",
    "- What ist PhiX?\n",
    "    - PhiX control v3 library is smal library for quality control\n",
    "    - Calibration control: phasing calculation, cross talk matrix generation, overall performance evaluation\n",
    "    - Run quality monitoring: due to its balanced nucleotide composition\n",
    "    - But should be removed to assemble the contigs\n",
    "- Almost 100 % of the data wasn't mapped to PhiX, so the run was quite short\n",
    "    - But there were files with higher error rate. (SRR15145662, SRR23378604, SRR23378605)\n",
    "\n",
    "#### Error correction \n",
    "- with tadpole.sh of BBMap, correction mode\n",
    "    - using given kmer counts and different algorithms\n",
    "    - with rollback=t option, contigs with higher coverages are obtained\n",
    "    - correct erros in read without extending or assemble them \n",
    "- Ran successfully\n",
    "- Rate of reads with errors mostly > 80%\n",
    "- No reduction in reads and bases\n",
    "- Correction rate mostly under 2 % of total errors detected\n",
    "\n",
    "#### Assembly\n",
    "- Assemble the reads to contigs with different k-mers, metagenome assembly mode\n",
    "- Run successful\n",
    "    - But don't forget to set the sbatch time limit to max (2-00:00), otherwise it might be quitted haha\n",
    "    - I had to rerun assembly for those canceled due to time limit\n",
    "        - SRR15145660\n",
    "        - SRR15145661\n",
    "        - SRR15145662\n",
    "        - SRR15145663\n",
    "        - SRR15145664\n",
    "        - SRR15145666\n",
    "        - SRR23378604\n",
    "        - SRR23378605\n",
    "        - SRR6667231\n",
    "\n",
    "#### QC\n",
    "- FastQC and MultiQC\n",
    "    - For Raw reads, QCed reads, PHIX removed reads, error corrected reads\n",
    "    - also for EC reads mapped to the min500bp, renamed, prokaryotic contigs. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Progress PacBio\n",
    "Assembled MAG from PacBio sequences in DATA/PacBio_Assembly directory\n",
    "#### Filtlong\n",
    "- QC and filtering\n",
    "- But generally every reads are more than 1 kb long\n",
    "\n",
    "#### Canu\n",
    "- Error correction, trimming and assembly in one pipeline\n",
    "    - error corrected files can also be used for other assembly pipelines like wtdbg2\n",
    "- Runs were successful\n",
    "    - check whether circular genomes are present \n",
    "        - look at the files with grep function\n",
    "    - but: found no circular genome found \n",
    "        - Try with ASG metagenomic raw data?\n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "grep \"^>\" ASSEMBLIES/Canu/SRR10983239/SRR10983239.unitigs.fasta | head -n 20\n",
    "grep \"suggestCircular=yes\" ASSEMBLIES/Canu/SRR10983242/SRR10983242.unitigs.fasta | head -n 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### wtdbg2\n",
    "- runs successful but used not trimmed reads\n",
    "- reran with trimmed reads (wtdbg_alt)\n",
    "    - run successful\n",
    "    - It would be interesting to see how different the results are\n",
    " \n",
    "\n",
    " #### metaFlye\n",
    " - assumes that reads are uncorrected\n",
    " - run complete\n",
    "\n",
    " #### Trycycler\n",
    "- Takes too long, so try if you have time to spare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Long read assembly QC\n",
    "- metaQUAST for metagenomic MAG from long-read sequences with comparison of multiple assembly pipelines\n",
    "- Results: \n",
    "    - No quality assessment possible for contigs from Canu and wtdbg2 (with EC reads) due to too low contig number (2-digits for Canu, 3 digits for wtdbg2 with ECed reads)\n",
    "    - wtdbg2 contigs with raw reads (not ECed) has good balance of QC parameter and contig number/total length\n",
    "    - MetaFlye with higher mismatch rate, duplication ratio, indels and error rate but much higher contigs number (4-digits) and more hits to references\n",
    "- TO-DO: rerun with BUSCO database for bacteria for better results\n",
    "- Only wtdbg2 (non-EC reads) contigs are used for further MAG assembly and analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    - check whether the sample contains no circular genome or the pipeline is not accurate: \n",
    "        - a PacBio raw read file from ASG database (ERR13615510) downloaded and ran through the canu pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quality control\n",
    "Quality assessment of reads of raw reads and after each processing steps\n",
    "Tool: FastQC & multiQC\n",
    "- FastQC\n",
    "    - takes fastq file and generate summary graphs and tables + summary html\n",
    "- MultiQC\n",
    "    - combine the results of the outputs of FastQC\n",
    "- Filtlong\n",
    "\n",
    "- MultiQC_summary reports for each steps are created in html format\n",
    "    - But not every samples are displayed in status checks hitmap plot\n",
    "- Results\n",
    "    - FastQC: Examples (for Illumina and PacBio): https://www.bioinformatics.babraham.ac.uk/projects/fastqc/    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# for interactive interface: instead of sbatch run it just on the \n",
    "srun --pty --x11 --mem=10G --partition=interactive --time=2-00:00 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipelines \n",
    "#### Canu\n",
    "![Canu pipeline workflow image](Assembly/Pics/canu_pipeline.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DEBUGGING\n",
    "#### Warning in slurm output file after running trimmomatic:\n",
    "Exception in thread \"Thread-0\" java.lang.RuntimeException: Sequence and quality length don't match: 'AAAGGCATCGGTTGTCAGGTTCGTTGCTATGGGTGTACGTAACCATTTCAATTTTTCGGGGCGTAGGGCTTAGTTTCCACGCGTTCAATGAGAGCAGACCACCGTGAAGAGCTTTGGAATAGCACTTCAGTGGCTTCTGGCCATGACCTCC' vs 'F:FFFFF,FFF,F:FFFFF,FFFFFFFFFFFFFFFFFFFFFFFF::F:FFFFFFF:FFFFFFFFFFFFF:FFF,FFFFFFFFFFFFFFFFFFFFFF,FFF:F:F,FFFF,:F:FFFFF,FFF::FF,,F,:FF:,,FF:FF,:F:FFF,F,:F,FF,:FFFFFFFFF:F:,FFFF,,FFF,:,,,F,,:F:F:::,,FF,:F,FF,:F:FFF:FFFFFF:FFFFFFFFFFFFFF'\n",
    "\tat org.usadellab.trimmomatic.fastq.FastqRecord.<init>(FastqRecord.java:25)\n",
    "\tat org.usadellab.trimmomatic.fastq.FastqParser.parseOne(FastqParser.java:89)\n",
    "\tat org.usadellab.trimmomatic.fastq.FastqParser.next(FastqParser.java:179)\n",
    "\tat org.usadellab.trimmomatic.threading.ParserWorker.run(ParserWorker.java:42)\n",
    "\tat java.base/java.lang.Thread.run(Thread.java:1570)\n",
    "Exception in thread \"Thread-1\" java.lang.RuntimeException: Sequence and quality length don't match: 'GGGGGGGGGGGGGGGGGGGGGTGGGGTAGGGTTTGTATAGTGGTTGGGGTGGGGGGAGTATTGGTTGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGTCACACATAAGCAACATTTCGAAGGGTATGGTGATTTGGAATGACAAGAGTGTAAGATCGTAAGAGCGTCGTGAAGGGAAAGA' vs ',:FF:F,:FF,FFFFF:FFFFF,:FFFF,FF,,FF::,,:F:,:FF::,FFFF,F:FF:,F:FFFFFFF,F,FFFFF,,FFF:FF,::FF,FF,:F:F:F,FFFF,F,FFFFFFF,::F,FFFFF,F,,FFF:F,:,FFFF,F,,,FFFFF'\n",
    "\tat org.usadellab.trimmomatic.fastq.FastqRecord.<init>(FastqRecord.java:25)\n",
    "\tat org.usadellab.trimmomatic.fastq.FastqParser.parseOne(FastqParser.java:89)\n",
    "\tat org.usadellab.trimmomatic.fastq.FastqParser.next(FastqParser.java:179)\n",
    "\tat org.usadellab.trimmomatic.threading.ParserWorker.run(ParserWorker.java:42)\n",
    "\tat java.base/java.lang.Thread.run(Thread.java:1570)\n",
    "\n",
    "##### Debugging\n",
    "bioawk -cfastx 'length($seq) != length($qual)' RAWDATA/SRR23378605_1.fq.gz |wc\n",
    "- output: 0    0    0\n",
    "- The lengths are not different, so look into the file \n",
    "\n",
    "\n",
    "(FastqDump) [smomw681@nesh-login3 DATA]$ zgrep -A 3 \"AAAGGCATCGGTTGTCAGGTTCGTTGCTATGGGTGTACGTAACCATTTCAATTTTTCGGGGCGTAGGGCTTAGTTTCCACGCGTTCAATGAGAGCAGACCACCGTGAAGAGCTTTGGAATAGCACTTCAGTGGCTTCTGGCCATGACCTCC\" RAWDATA/SRR23378605_1.fastq.gz\n",
    "AAAGGCATCGGTTGTCAGGTTCGTTGCTATGGGTGTACGTAACCATTTCAATTTTTCGGGGCGTAGGGCTTAGTTTCCACGCGTTCAATGAGAGCAGACCACCGTGAAGAGCTTTGGAATAGCACTTCAGTGGCTTCTGGCCATGACCTCC\n",
    "+SRR23378605.25279883 HWI-A00245_BSF_0734:2:2119:9064:32503 length=151\n",
    "F:FFFFF,FFF,F:FFFFF,FFFFFFFFFFFFFFFFFFFFFFFF::F:FFFFFFF:FFFFFFFFFFFFF:FFF,FFFFFFFFFFFFFFFFFFFFFF,FFF:F:F,FFFF,:F:\n",
    "\n",
    "(FastqDump) [smomw681@nesh-login3 DATA]$ zgrep -A 3 \"GGGGGGGGGGGGGGGGGGGGGTGGGGTAGGGTTTGTATAGTGGTTGGGGTGGGGGGAGTATTGGTTGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGGTCACACATAAGCAACATTTCGAAGGGTATGGTGATTTGGAATGACAAGAGTGTAAGATCGTAAGAGCGTCGTGAAGGGAAAGA\" RAWDATA/SRR23378605_1.fastq.gz\n",
    "gzip: RAWDATA/SRR23378605_1.fastq.gz: invalid compressed data--format violated\n",
    "\n",
    "- Conclusion: the raw fastq.gz file was corrupt\n",
    "\t- The files are downloaded anew and the problem was solved\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
